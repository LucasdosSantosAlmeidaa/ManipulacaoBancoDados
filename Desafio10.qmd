---
title: "Lab10"
format: html
editor: visual
---

```{r}
library(reticulate)

```

```{python}

import polars as pl

```

```{python}
# Este trecho de código lê o arquivo 'airports.csv'.
# Ele seleciona apenas as colunas essenciais para a análise: o código IATA do aeroporto,
# a cidade e o estado onde o aeroporto está localizado.
aeroportos = pl.read_csv("airports.csv",
                         columns = ["IATA_CODE", "CITY", "STATE"])
                         
aeroportos.head(2)
```



```{python}
# O código carrega dados de um arquivo Excel chamado "WDIEXCEL.xlsx".
# Especificamente, ele mira na aba (sheet) "Country" para obter informações sobre países.
wdi = pl.read_excel("WDIEXCEL.xlsx", sheet_name = "Country",
                    columns = ["Short Name", "Region"])
wdi.head(2)
```

```{python}
# Cria um pequeno DataFrame de exemplo para demonstrações de agregação e limpeza de dados.
df = pl.DataFrame({
    "grupo": ["A", "A", "B", "B", "C"],
    "valor1": [10, 15, 10, None, 25],
    "valor2": [5, None, 20, 30, None]
})
df
```

```{python}
# Seleciona e exibe a coluna 'valor1'.
df["valor1"]

```

```{python}
# Calcula a média da coluna 'valor1'.
# Por padrão, Polars ignora valores nulos ao calcular a média.
df["valor1"].mean()

```

```{python}
# Remove (descarta) explicitamente quaisquer valores nulos (missing values) presentes na Series 'valor1'.
# A Series resultante tem apenas os valores válidos (10, 15, 10, 25).
df["valor1"].drop_nulls()

```

```{python}
# Combina a remoção de nulos com o cálculo da média.
# Embora o .mean() já ignore nulos, esta é uma forma explícita de ver o conjunto de dados
# sendo limpo antes do cálculo. (O resultado numérico é o mesmo que o anterior).
df["valor1"].drop_nulls().mean()

```

```{python}
# Usa o método .select() para calcular múltiplas métricas de agregação.
df.select([
  pl.col("valor1").mean().alias("media_v1"),
  pl.col("valor2").mean()
])
```

Quais são as médias da variável `valor1` e o valor mínimo da variável `valor2` para cada um dos grupos definidos por `grupo`?

```{python}
# Realiza uma operação de 'group by' (agrupamento).
# Agrupa as linhas do DataFrame com base nos valores da coluna 'grupo' (A, B, C).
df.group_by("grupo").agg([
  pl.col("valor1").mean().alias("media_valor1"),
  pl.col("valor2").min().alias("min_valor2")
]).sort("grupo")
```

Calcule o percentual de vôos das cias. aéreas “AA” e “DL” que atrasaram pelo menos 30 minutos nas chegadas aos aeroportos “SEA”, “MIA” e “BWI”.

```{python}
# Lê o arquivo de dados de voos.
voos = pl.read_csv("flights.csv",
                   columns = ["AIRLINE", "ARRIVAL_DELAY", "DESTINATION_AIRPORT"],
                   dtypes = {"AIRLINE": pl.Utf8,
                             "ARRIVAL_DELAY": pl.Int32,
                             "DESTINATION_AIRPORT": pl.Utf8})
voos.shape
```

```{python}
voos.head(3)

```

Calcule o percentual de vôos das cias. aéreas “AA” e “DL” que atrasaram pelo menos 30 minutos nas chegadas aos aeroportos “SEA”, “MIA” e “BWI”.

```{python}
# Início do processamento da consulta usando uma cadeia de métodos (chaining).


resultado = (
  voos.drop_nulls(["AIRLINE", "DESTINATION_AIRPORT", "ARRIVAL_DELAY"])
  .filter(
    pl.col("AIRLINE").is_in(["AA", "DL"]) &
    pl.col("DESTINATION_AIRPORT").is_in(["SEA", "MIA", "BWI"])
    )
    .group_by(["AIRLINE", "DESTINATION_AIRPORT"])
    .agg([
      (pl.col("ARRIVAL_DELAY") > 30).mean().alias("atraso_medio")
      ])
)
```

```{python}
#Exibe o resultado da análise de atrasos.
# Os dados são ordenados pela coluna 'atraso_medio' para que o maior (ou menor) percentual
# de atrasos longos apareça no topo ou no final, facilitando a identificação.
resultado.sort("atraso_medio")

```

Aula de Dados Relacionais com Polars

```{python}
# Cria o DataFrame de clientes: uma tabela de dimensões simples.

clientes = pl.DataFrame({
    "cliente_id": [1, 2, 3, 4],
    "nome": ["Ana", "Bruno", "Clara", "Daniel"]
})

print(clientes)
```

```{python}
# Cria o DataFrame de pedidos (fatos), que tem a chave estrangeira 'cliente_id'.

pedidos = pl.DataFrame({
    "pedido_id": [101, 102, 103, 104, 105],
    "cliente_id": [1, 2, 3, 1, 5],
    "valor": [100.50, 250.75, 75.00, 130.00, 79.00]
})

print(pedidos)
```

```{python}
# Realiza um JOIN INTERNO ('inner').
# Apenas as linhas que têm 'cliente_id' correspondente em AMBOS os DataFrames são mantidas.
res_ij = clientes.join(pedidos, on="cliente_id", how="inner")
print(res_ij)
```

```{python}
# Realiza um JOIN À ESQUERDA ('left').
# Mantém TODAS as linhas de 'clientes' (tabela da esquerda).
# Adiciona as colunas de 'pedidos'. Se não houver correspondência, preenche com nulos.
res_lj = clientes.join(pedidos, on="cliente_id", how="left")
print(res_lj)
```

```{python}
# Realiza um JOIN À DIREITA ('right').
# Mantém TODAS as linhas de 'pedidos' (tabela da direita), inclusive a do 'cliente_id'=5.
# Adiciona as colunas de 'clientes'. Se não houver correspondência (como para o cliente 5), preenche com nulos.
res_rj = clientes.join(pedidos, on="cliente_id", how="right")
print(res_rj)
```

```{python}
# Realiza um JOIN COMPLETO EXTERNO ('outer').
# Mantém TODAS as linhas de AMBOS os DataFrames.
# Nulos são inseridos onde não há correspondência em qualquer um dos lados.
res_oj = clientes.join(pedidos, on="cliente_id", how="outer")
print(res_oj)
```

```{python}
# Realiza um JOIN CARTESIANO ('cross').
# Cada linha de 'clientes' é combinada com CADA linha de 'pedidos'.
# Isso resulta em um DataFrame com (linhas de clientes * linhas de pedidos) linhas.
res_cj = clientes.join(pedidos, how="cross")
print(res_cj)

```

```{python}
print(clientes)
```

```{python}
print(pedidos)
```

```{python}
res = res_ij.group_by(["nome", "cliente_id"]).agg(pl.col("valor").mean())
print(res)
```

```{python}
print(clientes)
```

```{python}
print(pedidos)
```

```{python}
# Utiliza o resultado do JOIN EXTERNO COMPLETO (res_oj) para uma análise mais complexa.

res = (res_oj.with_columns(pl.col("valor") > 100)
       .group_by("nome")
       .agg(pl.col("valor").sum()))
print(res)
```

```{python}
vendas = pl.DataFrame({
    "id_venda": [1, 2, 3],
    "id_cl": [1, 2, 1],
    "id_prod": [101, 102, 103],
    "qtde": [2, 1, 1]
})

detalhes_pedidos = pl.DataFrame({
    "id_ped": [201, 202, 203],
    "cl_id": [1, 2, 1],
    "id_prod": [101, 102, 104],
    "valor": [50.00, 75.00, 100.00]
})
```

```{python}
print(vendas)
```

```{python}
print(detalhes_pedidos)
```

```{python}
final = vendas.join(detalhes_pedidos,
                    left_on = ["id_cl", "id_prod"],
                    right_on = ["cl_id", "id_prod"],
                    how = "inner")
print(final)
```
